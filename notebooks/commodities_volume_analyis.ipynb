{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Analyze volume for all cattle commodities split by contract year and contract month.\n",
    "For each contract we plot the following:\n",
    "- Average Daily Nominal Trading Volume By Minute\n",
    "- Average Daily Normalized Trading Volume By Minute\n",
    "'''\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import numpy as np\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367be0dc-e598-4830-8945-b86a6f52f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotly as the plotting engine for pandas for convenience\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997fb35-5a25-4dbc-bb3d-9da2191128ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the csv files to process\n",
    "csv_files = []\n",
    "for file in os.listdir(\"../data/raw/firstratedata_futures\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        csv_files.append(file)\n",
    "csv_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c83e78-55a3-4b8c-9ade-3a2832412db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct two lists of unique contract months and years respectively\n",
    "contracts = list(map(lambda file: file[:-4], csv_files))\n",
    "unique_contract_years = list(set(map(lambda contract: contract[-2:], contracts)))\n",
    "unique_contract_years.sort()\n",
    "unique_contract_years = ['All'] + unique_contract_years\n",
    "unique_contract_months = list(set(map(lambda contract: contract[-3], contracts)))\n",
    "unique_contract_months.sort()\n",
    "unique_contract_months = ['All'] + unique_contract_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff16de3-f2b4-4828-95bd-389e09d2d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_filter_widget = widgets.ToggleButtons(\n",
    "    options=unique_contract_months,\n",
    "    description='Month:',\n",
    "    disabled=False,\n",
    "    button_style=''\n",
    ")\n",
    "display(month_filter_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f3002-69aa-46be-b137-123135b1c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_filter_widget = widgets.ToggleButtons(\n",
    "    options=unique_contract_years,\n",
    "    description='Year:',\n",
    "    disabled=False,\n",
    "    button_style=''\n",
    ")\n",
    "display(year_filter_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372fb73e-3435-4438-9029-6db731ad91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contracts_to_analyze = contracts\n",
    "if (month_filter_widget.value is not None) and (month_filter_widget.value != 'All'):\n",
    "    contracts_to_analyze = list(filter(lambda contract: contract[-3] == month_filter_widget.value, contracts_to_analyze))\n",
    "if (year_filter_widget.value is not None) and (year_filter_widget.value != 'All'):\n",
    "    contracts_to_analyze = list(filter(lambda contract: contract[-2:] == year_filter_widget.value, contracts_to_analyze))\n",
    "filenames_to_analyze = list(map(lambda contract: contract + '.csv', contracts_to_analyze))\n",
    "print('Analyzing the following files: ' + ', '.join(filenames_to_analyze))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_df(filename):\n",
    "    df_volume = pd.read_csv(f\"../data/raw/firstratedata_futures/{filename}\", parse_dates=['DateTime'], index_col=['DateTime'])\n",
    "    return df_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_trading_days(df):\n",
    "    '''Calculate the number of unique trading days in the dataset'''\n",
    "    unique_trading_days = df.index.map(lambda t: t.date()).unique()\n",
    "    return unique_trading_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbac537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_volume_by_minute(df):\n",
    "    '''Resample the data-set by minute filling in the gaps and summing the trading volume within each minute'''\n",
    "    df_volume_by_minute = df.resample('1T').sum()[[\"Volume\"]]\n",
    "    return df_volume_by_minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_minute(df_volume_by_minute):\n",
    "    '''Group minutes across days together so that we now have the total volume by minute across all days in the dataset'''\n",
    "    df_volume_by_minute_grouped = df_volume_by_minute.groupby(lambda x: x.time()).sum().rename(columns={'Volume':'Total Volume'})\n",
    "    return df_volume_by_minute_grouped\n",
    "    # df_volume_by_minute_grouped.iloc[0:5]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_vol_per_minute(df, num_unique_trading_days):\n",
    "    '''Calculate the average volume per minute by dividing the total volume per minute by the number of unique trading days'''\n",
    "    df['Daily Avg Volume'] = df.apply(lambda row: row / num_unique_trading_days )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b30dfc-1d46-43b6-bac3-b9d055209f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that returns an array of normalized values given an ndarray of nominal values\n",
    "def normalize_nd_array(to_normalize):\n",
    "    '''train the normalization'''\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(to_normalize)\n",
    "    # print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "    # normalize the dataset and print the first 5 rows\n",
    "    normalized = scaler.transform(to_normalize)\n",
    "    normalized = list(map(lambda x: x[0], normalized.tolist()))\n",
    "    # for i in range(5):\n",
    "    # \tprint(normalized[i])\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38a65c-97f8-47ab-9903-7f1eeee833aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_volume(df):\n",
    "    '''Create an array containing the series of total volume values'''\n",
    "    total_volume_values = df['Total Volume'].values\n",
    "    # Convert the array into a matrix (this format is needed for the normalization functions)\n",
    "    total_volume_matrix = total_volume_values.reshape((len(total_volume_values), 1))\n",
    "    # Return an array of normalized values\n",
    "    normalized_values = normalize_nd_array(total_volume_matrix)\n",
    "    # Add the column containing the normalized values to the dataframe\n",
    "    df_volume_by_minute_grouped['Total Volume Per Minute (Normalized)'] = normalized_values\n",
    "    # df_volume_by_minute_grouped.iloc[1420:1425]\n",
    "    return df_volume_by_minute_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5fd0f9-6e45-4969-8be8-5fe281ae2e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframes_for_volume_grouped_by_minute(df_volume_by_minute, unique_trading_days, contract_symbol):\n",
    "    '''\n",
    "    Create and populate an array of dataframes. Each dataframe contains one trading days worth of volume values grouped by minute\n",
    "    and normalized against just that days worth of activity\n",
    "    '''\n",
    "    frames = []\n",
    "    for i in trange(len(unique_trading_days), desc=f\"{contract_symbol} - Splitting into dataframes grouped by minute\"):\n",
    "        day=unique_trading_days[i]\n",
    "        string_date = day.strftime(\"%Y-%m-%d\")\n",
    "        days_df = df_volume_by_minute.loc[string_date]\n",
    "        volume_values = days_df['Volume'].values\n",
    "        volume_values = volume_values.reshape((len(volume_values), 1))\n",
    "        normalized_day_volume = normalize_nd_array(volume_values)\n",
    "        days_df['Volume Normalized Intraday'] = normalized_day_volume\n",
    "        frames.append(days_df.copy())\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e11b6-fd28-4a3c-b739-e0d2cafa04fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_to_single_df(frames):\n",
    "    '''Concatenate the entire array of dataframes back into one big dataframe that contains the Volume Normalized Intraday values for every minute of every day'''\n",
    "    df_intraday_normalized = pd.concat(frames)\n",
    "    return df_intraday_normalized\n",
    "    # Show a small sample\n",
    "    # df_intraday_normalized.iloc[170000:170005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b05ef4-5e21-42f3-8291-9c2a395bd054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the volume Normalized intraday Avg\n",
    "def calculate_normalized_vol_by_minute(intraday_summed, num_unique_trading_days):\n",
    "    return intraday_summed / num_unique_trading_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808531d0-acc4-4b3e-9f3a-d29766ddfb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_minute_sum_normalized_volumes(df_intraday_normalized):\n",
    "    '''Group by minute across all days summing the intraday normalized volumes'''\n",
    "    df_normalized_grouped_by_minute = df_intraday_normalized.groupby(lambda x: x.time()).sum().rename(columns={'Volume Normalized Intraday':'Volume Normalized Summed'})\n",
    "    # Add a column that shows the average intraday normalized volume for each minute\n",
    "    df_normalized_grouped_by_minute['Daily Avg Volume Normalized'] = df_normalized_grouped_by_minute.apply(\n",
    "        lambda row: calculate_normalized_vol_by_minute(row['Volume Normalized Summed'],\n",
    "                                                       num_unique_trading_days),\n",
    "        axis=1\n",
    "    )\n",
    "    return df_normalized_grouped_by_minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c728ba-269c-49d3-8023-fff0e9bc83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_df_grouped_by_minute():\n",
    "    '''Initialize an empty dataframe with no data and an index with a row for each minute of the day'''\n",
    "    date_range = pd.date_range(start='1/1/2021', end='1/02/2021', freq='T')[:-1]\n",
    "    new_df = pd.DataFrame(data={'DateTime':date_range}).set_index('DateTime')\n",
    "    new_df = new_df.groupby(lambda x: x.time()).sum()\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bef46f-e2be-48c8-ae76-2d73152ddfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each contract and perform analysis to create charts\n",
    "master_avg_daily_nominal_df = initialize_df_grouped_by_minute()\n",
    "master_avg_daily_normalized_df = initialize_df_grouped_by_minute()\n",
    "for i in trange(len(filenames_to_analyze), desc=f\"Overall Analysis\"):\n",
    "    file = filenames_to_analyze[i]\n",
    "    contract_symbol = file[:len(file) - 4]\n",
    "    df = convert_csv_to_df(file)\n",
    "    # print(\"Initial dataframe\")\n",
    "    # display(df)\n",
    "    unique_trading_days = get_unique_trading_days(df)\n",
    "    num_unique_trading_days = len(unique_trading_days)\n",
    "    # print(f\"Unique trading days = {num_unique_trading_days}\")\n",
    "    df_volume_by_minute = resample_volume_by_minute(df)\n",
    "    # print(f\"\\ndf_volume_by_minute {contract_symbol}\")\n",
    "    # display(df_volume_by_minute)\n",
    "    df_volume_by_minute_grouped = group_by_minute(df_volume_by_minute)\n",
    "    # print(\"\\ndf_volume_by_minute_grouped\")\n",
    "    # display(df_volume_by_minute_grouped)\n",
    "    df_volume_by_minute_grouped = calculate_avg_vol_per_minute(df_volume_by_minute_grouped, num_unique_trading_days)\n",
    "    # print(\"\\ndf_volume_by_minute_grouped\")\n",
    "    # display(df_volume_by_minute_grouped)\n",
    "    frames = create_dataframes_for_volume_grouped_by_minute(df_volume_by_minute, unique_trading_days, contract_symbol)\n",
    "    # Show a small sample\n",
    "    # print(\"\\nSample of volume normalized intraday\")\n",
    "    # display(frames[125][614:618])\n",
    "    df_intraday_normalized = concat_to_single_df(frames)\n",
    "    # Show a small sample\n",
    "    print(\"\\ndf_intraday_normalized sample\")\n",
    "    display(df_intraday_normalized.iloc[170000:170005])\n",
    "    df_normalized_grouped_by_minute = group_by_minute_sum_normalized_volumes(df_intraday_normalized)\n",
    "    # Show a small sample\n",
    "    print(\"\\ndf_normalized_grouped_by_minute\")\n",
    "    display(df_normalized_grouped_by_minute[500:510])\n",
    "    # Copy the columns from the intermediate dataframes to the master one which will be used for charting\n",
    "    master_avg_daily_nominal_df[f\"{contract_symbol}\"] = df_volume_by_minute_grouped['Daily Avg Volume'].copy()\n",
    "    master_avg_daily_normalized_df[f\"{contract_symbol}\"] = df_normalized_grouped_by_minute['Daily Avg Volume Normalized'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88753bf5-de0c-4782-8e28-a12a6353749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    figures = []\n",
    "    fig1 = master_avg_daily_nominal_df.plot(kind=\"line\", title=f\"Average Intraday Nominal Trading Volume By Minute\")\n",
    "    fig2 = master_avg_daily_normalized_df.plot(kind=\"line\", title=f\"Average Intraday Normalized Trading Volume By Minute\")\n",
    "    figures.append(fig1)\n",
    "    figures.append(fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae7539-8758-46e3-a85c-039f14a67e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the charts in the notebook\n",
    "for fig in figures:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab22a7-14cc-4780-857b-d6ffc661895d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.0"
  },
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
